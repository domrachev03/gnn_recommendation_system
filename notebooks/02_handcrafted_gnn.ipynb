{"metadata":{"accelerator":"GPU","colab":{"private_outputs":true,"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7092891,"sourceType":"datasetVersion","datasetId":4087587}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Recommender Systems with Graph Neural Networks in PyG\n\n> Note: this noteboot is an adapted version of those by Derrick Li, Peter Maldonado, Akram Sbaih as part of the Stanford CS224W course project.","metadata":{"id":"ktxdLosxtgZd"}},{"cell_type":"markdown","source":"## Setup\n\nFirst, we'll install the necessary packages.","metadata":{"id":"BoRvTQ1vtwcq"}},{"cell_type":"code","source":"%%capture\n!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n\n# !git clone https://github.com/pmaldonado/cs224w-project-data.git","metadata":{"id":"4p_Pj_D7t3Rk","execution":{"iopub.status.busy":"2023-12-02T19:29:07.072371Z","iopub.execute_input":"2023-12-02T19:29:07.073017Z","iopub.status.idle":"2023-12-02T19:29:33.280891Z","shell.execute_reply.started":"2023-12-02T19:29:07.072984Z","shell.execute_reply":"2023-12-02T19:29:33.279688Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"Next, let's import all of the modules that we'll use in this notebook.","metadata":{"id":"u_LPed5cuAEa"}},{"cell_type":"code","source":"# Standard library imports\nimport random\nimport time\n\n# Third-party imports\nimport matplotlib.pyplot as plt\nimport networkx as nx\nimport numpy as np\nimport pandas as pd\npd.set_option('display.max_colwidth', None)\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n# from torch.utils.data import Dataset, DataLoader\nimport torch_geometric\nfrom torch_geometric.nn.conv import MessagePassing\nfrom torch_geometric.utils import degree\n\nfrom tqdm.notebook import tqdm\nfrom sklearn import preprocessing as pp\nfrom sklearn.model_selection import train_test_split\nimport scipy.sparse as sp","metadata":{"id":"Y9fonQcxt3do","execution":{"iopub.status.busy":"2023-12-02T19:29:33.282796Z","iopub.execute_input":"2023-12-02T19:29:33.283116Z","iopub.status.idle":"2023-12-02T19:29:39.772926Z","shell.execute_reply.started":"2023-12-02T19:29:33.283088Z","shell.execute_reply":"2023-12-02T19:29:39.771932Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Lastly, we should double check that our environment is working as expected.","metadata":{"id":"nzLUutf7uNAS"}},{"cell_type":"code","source":"torch_geometric.__version__","metadata":{"id":"J_CDy1cbuF4_","execution":{"iopub.status.busy":"2023-12-02T19:29:39.774243Z","iopub.execute_input":"2023-12-02T19:29:39.775004Z","iopub.status.idle":"2023-12-02T19:29:39.782045Z","shell.execute_reply.started":"2023-12-02T19:29:39.774967Z","shell.execute_reply":"2023-12-02T19:29:39.781144Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"'2.4.0'"},"metadata":{}}]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"id":"b4pKT5jUt3pz","execution":{"iopub.status.busy":"2023-12-02T19:29:39.784316Z","iopub.execute_input":"2023-12-02T19:29:39.784603Z","iopub.status.idle":"2023-12-02T19:29:39.817014Z","shell.execute_reply.started":"2023-12-02T19:29:39.784579Z","shell.execute_reply":"2023-12-02T19:29:39.816259Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"device(type='cuda', index=0)"},"metadata":{}}]},{"cell_type":"markdown","source":"## Dataset and Preprocessing\n","metadata":{"id":"eYnQc9UH07Fg"}},{"cell_type":"markdown","source":"Let's start from loading u1 partition of the data:","metadata":{}},{"cell_type":"code","source":"columns_name=['user_id','item_id','rating','timestamp']\ndf_train, df_test = pd.read_csv(\"/kaggle/input/u111111/u1.base\",sep=\"\\t\",names=columns_name), pd.read_csv(\"/kaggle/input/u111111/u1.base\", sep=\"\\t\", names=columns_name)\ndf_train.head()","metadata":{"id":"D13_omigmeOi","execution":{"iopub.status.busy":"2023-12-02T19:29:39.817968Z","iopub.execute_input":"2023-12-02T19:29:39.818246Z","iopub.status.idle":"2023-12-02T19:29:39.953303Z","shell.execute_reply.started":"2023-12-02T19:29:39.818216Z","shell.execute_reply":"2023-12-02T19:29:39.952472Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"   user_id  item_id  rating  timestamp\n0        1        1       5  874965758\n1        1        2       3  876893171\n2        1        3       4  878542960\n3        1        4       3  876893119\n4        1        5       3  889751712","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>item_id</th>\n      <th>rating</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n      <td>874965758</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>876893171</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>878542960</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>4</td>\n      <td>3</td>\n      <td>876893119</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>5</td>\n      <td>3</td>\n      <td>889751712</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"n_users = df_train['user_id'].nunique()\nn_items = df_train['item_id'].nunique()\nprint(\"Number of Unique Users : \", n_users)\nprint(\"Number of unique Items : \", n_items)","metadata":{"id":"-WOF-cOAm5iO","execution":{"iopub.status.busy":"2023-12-02T19:29:39.954493Z","iopub.execute_input":"2023-12-02T19:29:39.954836Z","iopub.status.idle":"2023-12-02T19:29:39.964928Z","shell.execute_reply.started":"2023-12-02T19:29:39.954802Z","shell.execute_reply":"2023-12-02T19:29:39.964046Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Number of Unique Users :  943\nNumber of unique Items :  1650\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Minibatch Sampling\n\nExplain the scheme of minibatch positive and negative sample in some amount of prose.\n\nWe need to add `n_usr` to the sampled positive and negative items, since each node must have a unique id when using PyG.","metadata":{"id":"XNoblY5kxlv_"}},{"cell_type":"code","source":"def data_loader(data, batch_size, n_usr):\n    batched_data = data.sample(batch_size)\n    \n    return (\n        torch.LongTensor(list(batched_data['user_id'])).to(device),\n        torch.LongTensor(list(batched_data['item_id'])).to(device) + n_usr,\n        torch.LongTensor(list(batched_data['rating'])).to(device)\n    )\n\ndata_loader(df_train, 16, n_users)","metadata":{"id":"NQRGy-CJnOkg","execution":{"iopub.status.busy":"2023-12-02T19:29:39.966178Z","iopub.execute_input":"2023-12-02T19:29:39.966717Z","iopub.status.idle":"2023-12-02T19:29:43.073424Z","shell.execute_reply.started":"2023-12-02T19:29:39.966683Z","shell.execute_reply":"2023-12-02T19:29:43.072529Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"(tensor([860, 409,  94, 321, 378, 417, 847, 883, 795, 532, 381, 318, 169, 643,\n         425, 853], device='cuda:0'),\n tensor([1259, 2480, 1572, 1140, 1892, 1111, 2080, 1865, 1022, 1391, 1093, 1319,\n         1423, 1363, 1131, 1816], device='cuda:0'),\n tensor([3, 4, 4, 5, 3, 4, 5, 5, 2, 4, 4, 3, 4, 4, 3, 3], device='cuda:0'))"},"metadata":{}}]},{"cell_type":"markdown","source":"## Edge Index\n\nPyG represents graphs as sparse lists of node pairs. Since our graph is undirected, we need to include each edge twice, once for the edges from the users to the items and vice-versa.\n\nSimilar to above, we add `n_users` to the item tensor to ensure that every node in the graph has a unique identifier.","metadata":{"id":"vjHZg1Eu-MKs"}},{"cell_type":"code","source":"u_t = torch.LongTensor(df_train['user_id'])\ni_t = torch.LongTensor(df_train['item_id']) + n_users\nw_t = torch.LongTensor(df_train['rating'])\n\ntrain_edge_index = torch.stack((\n  torch.cat([u_t, i_t]),\n  torch.cat([i_t, u_t])\n)).to(device)\ntrain_weights = torch.cat([w_t, w_t])\ntrain_edge_index","metadata":{"id":"O3BkGyV9pkce","execution":{"iopub.status.busy":"2023-12-02T19:29:43.074727Z","iopub.execute_input":"2023-12-02T19:29:43.075107Z","iopub.status.idle":"2023-12-02T19:29:43.175705Z","shell.execute_reply.started":"2023-12-02T19:29:43.075074Z","shell.execute_reply":"2023-12-02T19:29:43.174836Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"tensor([[   1,    1,    1,  ..., 2131, 2171, 2273],\n        [ 944,  945,  946,  ...,  943,  943,  943]], device='cuda:0')"},"metadata":{}}]},{"cell_type":"markdown","source":"Let's confirm that the first and last edges match the middle two edges, but with the order of nodes swapped.","metadata":{"id":"_RxDUYJ2sXJe"}},{"cell_type":"code","source":"train_edge_index[:,0], train_edge_index[:,train_edge_index.shape[1]//2]","metadata":{"id":"Mq4NVs0_nOxh","execution":{"iopub.status.busy":"2023-12-02T19:29:43.176972Z","iopub.execute_input":"2023-12-02T19:29:43.177239Z","iopub.status.idle":"2023-12-02T19:29:43.189852Z","shell.execute_reply.started":"2023-12-02T19:29:43.177215Z","shell.execute_reply":"2023-12-02T19:29:43.188898Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"(tensor([  1, 944], device='cuda:0'), tensor([944,   1], device='cuda:0'))"},"metadata":{}}]},{"cell_type":"code","source":"train_weights[0:5], train_weights[train_weights.shape[0]//2:train_weights.shape[0]//2+5]","metadata":{"execution":{"iopub.status.busy":"2023-12-02T19:29:43.194018Z","iopub.execute_input":"2023-12-02T19:29:43.194554Z","iopub.status.idle":"2023-12-02T19:29:43.201182Z","shell.execute_reply.started":"2023-12-02T19:29:43.194530Z","shell.execute_reply":"2023-12-02T19:29:43.200195Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"(tensor([5, 3, 4, 3, 3]), tensor([5, 3, 4, 3, 3]))"},"metadata":{}}]},{"cell_type":"markdown","source":"## Model Architecture\n\nFirst, let's take a look at the graph convolutional layers that will power our recommender system GNN. Then, we can implement a wrapper to stack multiple convolutional layers.","metadata":{"id":"2ys1P7mtcr54"}},{"cell_type":"markdown","source":"### LightGCN Convolutional Layer\n\nThe LightGCN architecture is governed by the following rules:\n\n$$e_{u}^{(k+1)} = \\sum\\limits_{i \\in N_u} \\frac{1}{\\sqrt{|N_u|}\\sqrt{|N_i|}}e^{(k)}_i$$\n\n$$e_{i}^{(k+1)} = \\sum\\limits_{u \\in N_i} \\frac{1}{\\sqrt{|N_i|}\\sqrt{|N_u|}}e^{(k)}_u$$\nIn essence, the embedding for each node after a single LightGCN layer is the sum of the synthetic normalized embeddings of it's neighbors before the layer.","metadata":{"id":"49WD8SryyUds"}},{"cell_type":"markdown","source":"\nBriefly explain how the `MessagePassing` class works (look at colabs)\n\nWe can specify the type of aggregation our `MessagePassing` layer should use by passing in an `aggr=` argument in the layer initialization. Here we use `add` to specify summation aggregation of messages.\n\nNote that we could have manually defined our aggregation function by defining a function explicitly in the class:\n```\ndef aggregate(self, x, messages, index):\n  return torch_scatter.scatter(messages, index, self.node_dim, reduce=\"sum\")\n```\nThe `torch_scatter.scatter` function enables us to aggregate messages being sent to the same node. The `reduce=` argument specifies how to aggregate, while `index` has the same length as the `messages` tensor and maps from message to destination node.","metadata":{"id":"IcUsEulPtNNp"}},{"cell_type":"code","source":"class LightGCNConv(MessagePassing):\n  def __init__(self, **kwargs):\n    super().__init__(aggr='add')\n\n  def forward(self, x, edge_index, edge_weights):\n    # Compute normalization\n    from_, to_ = edge_index\n    print(f\"to_: {to_.shape}, edge_weights: {edge_weights.shape}, x: {x.shape}\")\n    deg = torch.zeros((x.shape[0], ), dtype=edge_weights.dtype, device=edge_weights.device).scatter_add_(0, to_, edge_weights)\n    deg_inv_sqrt = deg.pow(-0.5)\n    deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n    norm = deg_inv_sqrt[from_] * deg_inv_sqrt[to_]\n    \n    print(norm)\n    # Start propagating messages (no update after aggregation)\n    return self.propagate(edge_index, x=x, norm=norm)\n\n  def message(self, x_j, norm):\n    return norm.view(-1, 1) * x_j","metadata":{"id":"-aTMoHisNIh_","execution":{"iopub.status.busy":"2023-12-02T19:29:43.202213Z","iopub.execute_input":"2023-12-02T19:29:43.202443Z","iopub.status.idle":"2023-12-02T19:29:43.210036Z","shell.execute_reply.started":"2023-12-02T19:29:43.202422Z","shell.execute_reply":"2023-12-02T19:29:43.209145Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"Let's test out our implementation of the LightGCN convolution by applying it to a small bipartite graph.\n\nThis sample graph is undirected, and node 0 is connected to nodes 2 and 3 while node 1 is connected to 3 and 4.","metadata":{"id":"P0Lrwz-4yei9"}},{"cell_type":"code","source":"test_x = torch.Tensor(np.eye(5))\ntest_edge_index = torch.LongTensor(np.array([\n  [0, 0, 1, 1, 2, 3, 3, 4],\n  [2, 3, 3, 4, 0, 0, 1, 1]\n]))\ntest_edge_weights = torch.LongTensor([1, 2, 3, 4, 1, 2, 3, 4])\nLightGCNConv()(test_x, test_edge_index, test_edge_weights)","metadata":{"id":"bgcrWvgkhxQR","execution":{"iopub.status.busy":"2023-12-02T19:29:43.211197Z","iopub.execute_input":"2023-12-02T19:29:43.211571Z","iopub.status.idle":"2023-12-02T19:29:43.258696Z","shell.execute_reply.started":"2023-12-02T19:29:43.211545Z","shell.execute_reply":"2023-12-02T19:29:43.257807Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"to_: torch.Size([8]), edge_weights: torch.Size([8]), x: torch.Size([5, 5])\ntensor([0.5774, 0.2582, 0.1690, 0.1890, 0.5774, 0.2582, 0.1690, 0.1890])\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"tensor([[0.0000, 0.0000, 0.5774, 0.2582, 0.0000],\n        [0.0000, 0.0000, 0.0000, 0.1690, 0.1890],\n        [0.5774, 0.0000, 0.0000, 0.0000, 0.0000],\n        [0.2582, 0.1690, 0.0000, 0.0000, 0.0000],\n        [0.0000, 0.1890, 0.0000, 0.0000, 0.0000]])"},"metadata":{}}]},{"cell_type":"markdown","source":"Notice how each node has an initial feature vector corresponding to a one-hot encoding at the index of their id.\n\nAs we expected, node 0 received messages (and so has non-zero features at the corresponding indicies) from nodes 2 and 3. We can easily verify that nodes 1, 2, 3, and 4 also received messages from their precisely neighbors.","metadata":{"id":"e3CtZKN-yvIQ"}},{"cell_type":"markdown","source":"### NGCF Layer\n\nNGCF is an older architecture than LightGCN that originated by researchers who applied [Graph Convolutional Networks (GCNs)]() to recommender systems. LightGCN functions the same as NGCF, but removes the learnable linear layers, non-linear activation, and dropout.\n\nOne layer of NGCF updates user and item embeddings as follows:\n\n$$e_{u}^{(k+1)} = \\sigma\\left(W_1 e_u^{(k)} + \\sum\\limits_{i \\in N_u} \\frac{1}{\\sqrt{|N_u|}\\sqrt{|N_i|}}(W_1e^{(k)}_i + W_2(e^{(k)}_i \\odot e^{(k)}_u))\\right)$$\n\n$$e_{i}^{(k+1)} = \\sigma\\left(W_1 e_i^{(k)} + \\sum\\limits_{u \\in N_i} \\frac{1}{\\sqrt{|N_i|}\\sqrt{|N_u|}}(W_1e^{(k)}_u + W_2(e^{(k)}_u \\odot e^{(k)}_i))\\right)$$\n\nTypically, NGCF is implemented with dropout before the activation and with an activation function $\\sigma$ of LeakyReLU.","metadata":{"id":"0BIVMYyiyPHJ"}},{"cell_type":"code","source":"class NGCFConv(MessagePassing):\n  def __init__(self, latent_dim, dropout, bias=True, **kwargs):\n    super(NGCFConv, self).__init__(aggr='add', **kwargs)\n\n    self.dropout = dropout\n\n    self.lin_1 = nn.Linear(latent_dim, latent_dim, bias=bias)\n    self.lin_2 = nn.Linear(latent_dim, latent_dim, bias=bias)\n\n    self.init_parameters()\n\n\n  def init_parameters(self):\n    nn.init.xavier_uniform_(self.lin_1.weight)\n    nn.init.xavier_uniform_(self.lin_2.weight)\n\n\n  def forward(self, x, edge_index, edge_weights):\n    # Compute normalization\n    from_, to_ = edge_index\n    deg = torch.zeros((x.shape[0], ), dtype=edge_weights.dtype, device=edge_weights.device).scatter_add_(0, to_, edge_weights)\n    deg_inv_sqrt = deg.pow(-0.5)\n    deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n    norm = deg_inv_sqrt[from_] * deg_inv_sqrt[to_]\n\n    # Start propagating messages\n    out = self.propagate(edge_index, x=(x, x), norm=norm)\n\n    # Perform update after aggregation\n    out += self.lin_1(x)\n    out = F.dropout(out, self.dropout, self.training)\n    return F.leaky_relu(out)\n\n\n  def message(self, x_j, x_i, norm):\n    return norm.view(-1, 1) * (self.lin_1(x_j) + self.lin_2(x_j * x_i))","metadata":{"id":"u728UyYfOczG","execution":{"iopub.status.busy":"2023-12-02T19:29:43.259774Z","iopub.execute_input":"2023-12-02T19:29:43.260028Z","iopub.status.idle":"2023-12-02T19:29:43.269746Z","shell.execute_reply.started":"2023-12-02T19:29:43.260005Z","shell.execute_reply":"2023-12-02T19:29:43.268838Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"test_x = torch.Tensor(np.eye(5))\ntest_edge_index = torch.LongTensor(np.array([\n  [0, 0, 1, 1, 2, 3, 3, 4],\n  [2, 3, 3, 4, 0, 0, 1, 1]\n]))\ntest_edge_weights = torch.LongTensor([1, 2, 3, 4, 1, 2, 3, 4])\nNGCFConv(5, 0.1)(test_x, test_edge_index, test_edge_weights)","metadata":{"execution":{"iopub.status.busy":"2023-12-02T19:29:43.270852Z","iopub.execute_input":"2023-12-02T19:29:43.271109Z","iopub.status.idle":"2023-12-02T19:29:43.331183Z","shell.execute_reply.started":"2023-12-02T19:29:43.271086Z","shell.execute_reply":"2023-12-02T19:29:43.330335Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"tensor([[-0.0066, -0.0014,  0.7770, -0.0075, -0.0127],\n        [ 0.3170,  0.1745,  0.4587, -0.0000, -0.0132],\n        [-0.0022, -0.0063,  0.1591, -0.0000, -0.0000],\n        [ 0.0000,  0.0000,  1.3450, -0.0041, -0.0039],\n        [-0.0085,  0.0289,  0.1834,  0.3455, -0.0067]],\n       grad_fn=<LeakyReluBackward0>)"},"metadata":{}}]},{"cell_type":"markdown","source":"### Recommender System GNN\n\nFor this tutorial, we will be using the following class, `RecSysGNN` in order to stack the NGCF or LightGCN convolutional layers. Some considerations that can be made for tweaking the models are the number of layers of your model and dropout. The more number of layers you add to the model, the more your model will \"diffuse\" information of recommendations made from nodes that are `n`-hops away in a model that uses `n` layers. Dropout can be tweaked to try out different regularization schemes.\n\nNotice that our forward function works differently from most neural networks by forward propagating embeddings for all nodes in the graph. This is because the embeddings for a given node depend on the embeddings of it's `n`-hop neighborhood, so they need to be propagated as well.","metadata":{"id":"I2tW9FJFqNjn"}},{"cell_type":"code","source":"class RecSysGNN(nn.Module):\n  def __init__(\n      self,\n      latent_dim,\n      num_layers,\n      num_users,\n      num_items,\n      model, # 'NGCF' or 'LightGCN'\n      dropout=0.1 # Only used in NGCF\n  ):\n    super(RecSysGNN, self).__init__()\n\n    assert (model == 'NGCF' or model == 'LightGCN'), \\\n        'Model must be NGCF or LightGCN'\n    self.model = model\n    self.embedding = nn.Embedding(num_users + num_items, latent_dim)\n\n    if self.model == 'NGCF':\n      self.convs = nn.ModuleList(\n        NGCFConv(latent_dim, dropout=dropout) for _ in range(num_layers)\n      )\n    else:\n      self.convs = nn.ModuleList(LightGCNConv() for _ in range(num_layers))\n\n    self.init_parameters()\n\n\n  def init_parameters(self):\n    if self.model == 'NGCF':\n      nn.init.xavier_uniform_(self.embedding.weight, gain=1)\n    else:\n      # Authors of LightGCN report higher results with normal initialization\n      nn.init.normal_(self.embedding.weight, std=0.1)\n\n\n  def forward(self, edge_index, edge_weights):\n    emb0 = self.embedding.weight\n    embs = [emb0]\n\n    emb = emb0\n    for conv in self.convs:\n      emb = conv(x=emb, edge_index=edge_index, edge_weights=edge_weights)\n      embs.append(emb)\n\n    out = (\n      torch.cat(embs, dim=-1) if self.model == 'NGCF'\n      else torch.mean(torch.stack(embs, dim=0), dim=0)\n    )\n\n    return emb0, out\n\n\n  def encode_minibatch(self, users, items, edge_index, edge_weight):\n    emb0, out = self(edge_index, edge_weight)\n    return (\n        out[users],\n        out[items],\n        emb0[users],\n        emb0[items]\n    )","metadata":{"id":"nT5LTkI8Ml1c","execution":{"iopub.status.busy":"2023-12-02T19:29:43.332158Z","iopub.execute_input":"2023-12-02T19:29:43.332422Z","iopub.status.idle":"2023-12-02T19:29:43.344214Z","shell.execute_reply.started":"2023-12-02T19:29:43.332398Z","shell.execute_reply":"2023-12-02T19:29:43.343400Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## Loss function and metrics\n\nWe implement both the Bayesian Personalized Ranking loss function for a single minibatch of users, positive items, and negative items, as well as the precision@K and recall@K metrics.","metadata":{"id":"dyqEQ6kfCY5V"}},{"cell_type":"code","source":"def compute_bpr_loss(users, users_emb, item_emb, users_emb0, item_emb0):\n  # compute loss from initial embeddings, used for regulization\n  reg_loss = (1 / 2) * (\n    user_emb0.norm().pow(2) +\n    item_emb0.norm().pow(2)\n  ) / float(len(users))\n\n  # compute BPR loss from user, positive item, and negative item embeddings\n  pos_scores = torch.mul(users_emb, item_emb).sum(dim=1)\n  \n  bpr_loss = torch.mean(F.softplus(users_emb))\n\n  return bpr_loss, reg_loss","metadata":{"id":"bwrPmvXPow5q","execution":{"iopub.status.busy":"2023-12-02T19:29:43.345439Z","iopub.execute_input":"2023-12-02T19:29:43.345711Z","iopub.status.idle":"2023-12-02T19:29:43.356084Z","shell.execute_reply.started":"2023-12-02T19:29:43.345688Z","shell.execute_reply":"2023-12-02T19:29:43.355264Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def get_metrics(user_Embed_wts, item_Embed_wts, n_users, n_items, train_data, test_data, K):\n    test_user_ids = torch.LongTensor(test_data['user_id_idx'].unique())\n    # compute the score of all user-item pairs\n    relevance_score = torch.matmul(user_Embed_wts, torch.transpose(item_Embed_wts,0, 1))\n\n    # create dense tensor of all user-item interactions\n    i = torch.stack((\n    torch.LongTensor(train_df['user_id_idx'].values),\n    torch.LongTensor(train_df['item_id_idx'].values)\n    ))\n    v = torch.ones((len(train_df)), dtype=torch.float64)\n    interactions_t = torch.sparse.FloatTensor(i, v, (n_users, n_items))\\\n      .to_dense().to(device)\n\n    # mask out training user-item interactions from metric computation\n    relevance_score = torch.mul(relevance_score, (1 - interactions_t))\n\n    # compute top scoring items for each user\n    topk_relevance_indices = torch.topk(relevance_score, K).indices\n    topk_relevance_indices_df = pd.DataFrame(topk_relevance_indices.cpu().numpy(),columns =['top_indx_'+str(x+1) for x in range(K)])\n    topk_relevance_indices_df['user_ID'] = topk_relevance_indices_df.index\n    topk_relevance_indices_df['top_rlvnt_itm'] = topk_relevance_indices_df[['top_indx_'+str(x+1) for x in range(K)]].values.tolist()\n    topk_relevance_indices_df = topk_relevance_indices_df[['user_ID','top_rlvnt_itm']]\n\n    # measure overlap between recommended (top-scoring) and held-out user-item\n    # interactions\n    test_interacted_items = test_data.groupby('user_id_idx')['item_id_idx'].apply(list).reset_index()\n    metrics_df = pd.merge(test_interacted_items,topk_relevance_indices_df, how= 'left', left_on = 'user_id_idx',right_on = ['user_ID'])\n    metrics_df['intrsctn_itm'] = [list(set(a).intersection(b)) for a, b in zip(metrics_df.item_id_idx, metrics_df.top_rlvnt_itm)]\n\n    metrics_df['recall'] = metrics_df.apply(lambda x : len(x['intrsctn_itm'])/len(x['item_id_idx']), axis = 1)\n    metrics_df['precision'] = metrics_df.apply(lambda x : len(x['intrsctn_itm'])/K, axis = 1)\n\n    return metrics_df['recall'].mean(), metrics_df['precision'].mean()","metadata":{"id":"oHuXurG8mezC","execution":{"iopub.status.busy":"2023-12-02T19:29:43.357397Z","iopub.execute_input":"2023-12-02T19:29:43.357687Z","iopub.status.idle":"2023-12-02T19:29:43.369092Z","shell.execute_reply.started":"2023-12-02T19:29:43.357664Z","shell.execute_reply":"2023-12-02T19:29:43.368273Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"## Train and evaluate models\n\nNow that we've implemented both LightGCN and NGCF in PyG, we can train and evaluate their performance!","metadata":{"id":"_qOC3fF9m6cH"}},{"cell_type":"code","source":"latent_dim = 64\nn_layers = 3\n\nEPOCHS = 50\nBATCH_SIZE = 1024\nDECAY = 0.0001\nLR = 0.005\nK = 20","metadata":{"id":"MZtgfxxIm5nL","execution":{"iopub.status.busy":"2023-12-02T19:29:43.370014Z","iopub.execute_input":"2023-12-02T19:29:43.370258Z","iopub.status.idle":"2023-12-02T19:29:43.382645Z","shell.execute_reply.started":"2023-12-02T19:29:43.370235Z","shell.execute_reply":"2023-12-02T19:29:43.381769Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"train_weights = train_weights.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-12-02T19:29:43.383839Z","iopub.execute_input":"2023-12-02T19:29:43.384107Z","iopub.status.idle":"2023-12-02T19:29:43.392089Z","shell.execute_reply.started":"2023-12-02T19:29:43.384084Z","shell.execute_reply":"2023-12-02T19:29:43.391393Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def train_and_eval(model, optimizer, train_df):\n    loss_list_epoch = []\n    bpr_loss_list_epoch = []\n    reg_loss_list_epoch = []\n\n    recall_list = []\n    precision_list = []\n\n    for epoch in tqdm(range(EPOCHS)):\n        n_batch = int(len(train_df)/BATCH_SIZE)\n\n        final_loss_list = []\n        bpr_loss_list = []\n        reg_loss_list = []\n\n        model.train()\n        for batch_idx in range(n_batch):\n            optimizer.zero_grad()\n\n            users, items, weights = data_loader(train_df, BATCH_SIZE, n_users)\n            print(f\"users: {users.shape}, items: {items.shape}, weights: {weights.shape}, train_edge_index: {train_edge_index.shape}\")\n            users_emb, item_emb, userEmb0, itemEmb0 = model.encode_minibatch(users, items, train_edge_index, train_weights)\n           \n            bpr_loss, reg_loss = compute_bpr_loss(\n                users, users_emb, item_emb, userEmb0,  itemEmb0\n            )\n            reg_loss = DECAY * reg_loss\n            final_loss = bpr_loss + reg_loss\n\n            final_loss.backward()\n            optimizer.step()\n\n            final_loss_list.append(final_loss.item())\n            bpr_loss_list.append(bpr_loss.item())\n            reg_loss_list.append(reg_loss.item())\n\n        model.eval()\n        with torch.no_grad():\n            _, out = model(train_edge_index, weights)\n            final_user_Embed, final_item_Embed = torch.split(out, (n_users, n_items))\n            test_topK_recall, test_topK_precision = get_metrics(\n                final_user_Embed, final_item_Embed, n_users, n_items, train_df, test_df, K\n            )\n\n        loss_list_epoch.append(round(np.mean(final_loss_list),4))\n        bpr_loss_list_epoch.append(round(np.mean(bpr_loss_list),4))\n        reg_loss_list_epoch.append(round(np.mean(reg_loss_list),4))\n\n        recall_list.append(round(test_topK_recall,4))\n        precision_list.append(round(test_topK_precision,4))\n\n    return (\n        loss_list_epoch,\n        bpr_loss_list_epoch,\n        reg_loss_list_epoch,\n        recall_list,\n        precision_list\n    )","metadata":{"id":"B5HB_FX5pdgv","execution":{"iopub.status.busy":"2023-12-02T19:29:43.393312Z","iopub.execute_input":"2023-12-02T19:29:43.393592Z","iopub.status.idle":"2023-12-02T19:29:43.404879Z","shell.execute_reply.started":"2023-12-02T19:29:43.393568Z","shell.execute_reply":"2023-12-02T19:29:43.404007Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"### Train and eval LightGCN","metadata":{"id":"Z4xJSiBiznki"}},{"cell_type":"code","source":"lightgcn = RecSysGNN(\n  latent_dim=latent_dim,\n  num_layers=n_layers,\n  num_users=n_users,\n  num_items=n_items,\n  model='LightGCN'\n)\nlightgcn.to(device)\n\noptimizer = torch.optim.Adam(lightgcn.parameters(), lr=LR)\nprint(\"Size of Learnable Embedding : \", [x.shape for x in list(lightgcn.parameters())])","metadata":{"id":"eKBv9eXongux","execution":{"iopub.status.busy":"2023-12-02T19:29:43.406069Z","iopub.execute_input":"2023-12-02T19:29:43.406336Z","iopub.status.idle":"2023-12-02T19:29:43.424432Z","shell.execute_reply.started":"2023-12-02T19:29:43.406313Z","shell.execute_reply":"2023-12-02T19:29:43.423516Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Size of Learnable Embedding :  [torch.Size([2593, 64])]\n","output_type":"stream"}]},{"cell_type":"code","source":"light_loss, light_bpr, light_reg, light_recall, light_precision = train_and_eval(lightgcn, optimizer, df_train)","metadata":{"id":"iXfsuJlcy3FT","execution":{"iopub.status.busy":"2023-12-02T19:29:43.425538Z","iopub.execute_input":"2023-12-02T19:29:43.426417Z","iopub.status.idle":"2023-12-02T19:29:44.439909Z","shell.execute_reply.started":"2023-12-02T19:29:43.426392Z","shell.execute_reply":"2023-12-02T19:29:44.438182Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46ea495387de44e689693082307c0d68"}},"metadata":{}},{"name":"stdout","text":"users: torch.Size([1024]), items: torch.Size([1024]), weights: torch.Size([1024]), train_edge_index: torch.Size([2, 160000])\nto_: torch.Size([160000]), edge_weights: torch.Size([160000]), x: torch.Size([2593, 64])\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/src/pytorch/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [137,0,0], thread: [5,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:144: operator(): block: [137,0,0], thread: [6,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m light_loss, light_bpr, light_reg, light_recall, light_precision \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlightgcn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[20], line 22\u001b[0m, in \u001b[0;36mtrain_and_eval\u001b[0;34m(model, optimizer, train_df)\u001b[0m\n\u001b[1;32m     20\u001b[0m users, items, weights \u001b[38;5;241m=\u001b[39m data_loader(train_df, BATCH_SIZE, n_users)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musers: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00musers\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, items: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitems\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, weights: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweights\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, train_edge_index: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_edge_index\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m users_emb, item_emb, userEmb0, itemEmb0 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_minibatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43musers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitems\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_edge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m bpr_loss, reg_loss \u001b[38;5;241m=\u001b[39m compute_bpr_loss(\n\u001b[1;32m     25\u001b[0m     users, users_emb, item_emb, userEmb0,  itemEmb0\n\u001b[1;32m     26\u001b[0m )\n\u001b[1;32m     27\u001b[0m reg_loss \u001b[38;5;241m=\u001b[39m DECAY \u001b[38;5;241m*\u001b[39m reg_loss\n","Cell \u001b[0;32mIn[15], line 54\u001b[0m, in \u001b[0;36mRecSysGNN.encode_minibatch\u001b[0;34m(self, users, items, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode_minibatch\u001b[39m(\u001b[38;5;28mself\u001b[39m, users, items, edge_index, edge_weight):\n\u001b[0;32m---> 54\u001b[0m   emb0, out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m     56\u001b[0m       out[users],\n\u001b[1;32m     57\u001b[0m       out[items],\n\u001b[1;32m     58\u001b[0m       emb0[users],\n\u001b[1;32m     59\u001b[0m       emb0[items]\n\u001b[1;32m     60\u001b[0m   )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","Cell \u001b[0;32mIn[15], line 42\u001b[0m, in \u001b[0;36mRecSysGNN.forward\u001b[0;34m(self, edge_index, edge_weights)\u001b[0m\n\u001b[1;32m     40\u001b[0m emb \u001b[38;5;241m=\u001b[39m emb0\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m conv \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvs:\n\u001b[0;32m---> 42\u001b[0m   emb \u001b[38;5;241m=\u001b[39m \u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43memb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m   embs\u001b[38;5;241m.\u001b[39mappend(emb)\n\u001b[1;32m     45\u001b[0m out \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     46\u001b[0m   torch\u001b[38;5;241m.\u001b[39mcat(embs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNGCF\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     47\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mmean(torch\u001b[38;5;241m.\u001b[39mstack(embs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     48\u001b[0m )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","Cell \u001b[0;32mIn[11], line 11\u001b[0m, in \u001b[0;36mLightGCNConv.forward\u001b[0;34m(self, x, edge_index, edge_weights)\u001b[0m\n\u001b[1;32m      9\u001b[0m deg \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros((x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], ), dtype\u001b[38;5;241m=\u001b[39medge_weights\u001b[38;5;241m.\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39medge_weights\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mscatter_add_(\u001b[38;5;241m0\u001b[39m, to_, edge_weights)\n\u001b[1;32m     10\u001b[0m deg_inv_sqrt \u001b[38;5;241m=\u001b[39m deg\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m deg_inv_sqrt[\u001b[43mdeg_inv_sqrt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     12\u001b[0m norm \u001b[38;5;241m=\u001b[39m deg_inv_sqrt[from_] \u001b[38;5;241m*\u001b[39m deg_inv_sqrt[to_]\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(norm)\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"],"ename":"RuntimeError","evalue":"CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n","output_type":"error"}]},{"cell_type":"code","source":"epoch_list = [(i+1) for i in range(EPOCHS)]","metadata":{"id":"vCOJY4XST38b","execution":{"iopub.status.busy":"2023-12-02T19:29:44.440765Z","iopub.status.idle":"2023-12-02T19:29:44.441118Z","shell.execute_reply.started":"2023-12-02T19:29:44.440951Z","shell.execute_reply":"2023-12-02T19:29:44.440967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(epoch_list, light_loss, label='Total Training Loss')\nplt.plot(epoch_list, light_bpr, label='BPR Training Loss')\nplt.plot(epoch_list, light_reg, label='Reg Training Loss')\n\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()","metadata":{"id":"Z5P2Zf6yT4Uu","execution":{"iopub.status.busy":"2023-12-02T19:29:44.442737Z","iopub.status.idle":"2023-12-02T19:29:44.443077Z","shell.execute_reply.started":"2023-12-02T19:29:44.442916Z","shell.execute_reply":"2023-12-02T19:29:44.442932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(epoch_list, light_recall, label='Recall')\nplt.plot(epoch_list, light_precision, label='Precision')\nplt.xlabel('Epoch')\nplt.ylabel('Metrics')\nplt.legend()","metadata":{"id":"I1Quk5mahJ1n","execution":{"iopub.status.busy":"2023-12-02T19:29:44.444259Z","iopub.status.idle":"2023-12-02T19:29:44.444600Z","shell.execute_reply.started":"2023-12-02T19:29:44.444413Z","shell.execute_reply":"2023-12-02T19:29:44.444427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train and eval NGCF","metadata":{"id":"yl6OL1UPzqju"}},{"cell_type":"code","source":"ngcf = RecSysGNN(\n  latent_dim=latent_dim,\n  num_layers=n_layers,\n  num_users=n_users,\n  num_items=n_items,\n  model='NGCF'\n)\nngcf.to(device)\n\noptimizer = torch.optim.Adam(ngcf.parameters(), lr=LR)\nprint(\"Size of Learnable Embedding : \", [x.shape for x in list(ngcf.parameters())])","metadata":{"id":"wwO_h55Jzj4J","execution":{"iopub.status.busy":"2023-12-02T19:29:44.446095Z","iopub.status.idle":"2023-12-02T19:29:44.446428Z","shell.execute_reply.started":"2023-12-02T19:29:44.446265Z","shell.execute_reply":"2023-12-02T19:29:44.446281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ngcf_loss, ngcf_bpr, ngcf_reg, ngcf_recall, ngcf_precision = train_and_eval(ngcf, optimizer, train_df)","metadata":{"id":"KUtZEhAEzjrA","execution":{"iopub.status.busy":"2023-12-02T19:29:44.447544Z","iopub.status.idle":"2023-12-02T19:29:44.447870Z","shell.execute_reply.started":"2023-12-02T19:29:44.447695Z","shell.execute_reply":"2023-12-02T19:29:44.447724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epoch_list = [(i+1) for i in range(EPOCHS)]","metadata":{"id":"ENivAkwTzjcP","execution":{"iopub.status.busy":"2023-12-02T19:29:44.448679Z","iopub.status.idle":"2023-12-02T19:29:44.448984Z","shell.execute_reply.started":"2023-12-02T19:29:44.448833Z","shell.execute_reply":"2023-12-02T19:29:44.448847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(epoch_list, ngcf_loss, label='Total Training Loss')\nplt.plot(epoch_list, ngcf_bpr, label='BPR Training Loss')\nplt.plot(epoch_list, ngcf_reg, label='Reg Training Loss')\n\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()","metadata":{"id":"3MxNmjo-T4mg","execution":{"iopub.status.busy":"2023-12-02T19:29:44.450880Z","iopub.status.idle":"2023-12-02T19:29:44.451187Z","shell.execute_reply.started":"2023-12-02T19:29:44.451035Z","shell.execute_reply":"2023-12-02T19:29:44.451049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(epoch_list, ngcf_recall, label='Recall')\nplt.plot(epoch_list, ngcf_precision, label='Precision')\nplt.xlabel('Epoch')\nplt.ylabel('Metrics')\nplt.legend()","metadata":{"id":"jnVhVglYpd7G","execution":{"iopub.status.busy":"2023-12-02T19:29:44.452163Z","iopub.status.idle":"2023-12-02T19:29:44.452499Z","shell.execute_reply.started":"2023-12-02T19:29:44.452320Z","shell.execute_reply":"2023-12-02T19:29:44.452335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Compare model performance","metadata":{"id":"myUn4-Sr26KT"}},{"cell_type":"code","source":"max(light_precision), max(light_recall)","metadata":{"id":"6MY7QibZ6NNJ","execution":{"iopub.status.busy":"2023-12-02T19:29:44.453763Z","iopub.status.idle":"2023-12-02T19:29:44.454086Z","shell.execute_reply.started":"2023-12-02T19:29:44.453926Z","shell.execute_reply":"2023-12-02T19:29:44.453942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max(ngcf_precision), max(ngcf_recall)","metadata":{"id":"hbxiFcIe3BAu","execution":{"iopub.status.busy":"2023-12-02T19:29:44.455035Z","iopub.status.idle":"2023-12-02T19:29:44.455341Z","shell.execute_reply.started":"2023-12-02T19:29:44.455182Z","shell.execute_reply":"2023-12-02T19:29:44.455197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Paper References\n\n1. Harper, F. Maxwell, and Konstan, Joseph A. “The MovieLensDatasets: History and Context.” ACM Transactions on Interactive Intelligence Systems (TiiS) 5, 4. 2015.\n2. He, Xiangnan, et al. “LightGCN: Simplifying and powering graph convolution network for recommendation.” Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval. 2020.\n3. Wang, Xiang, et al. “Neural graph collaborative filtering.” Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval. 2019.\n\n## Code References\n\nWe thank the authors of the following codebases and notebooks, from which parts of this tutorial were inspired or adapted.\n\n- https://www.kaggle.com/dipanjandas96/lightgcn-pytorch-from-scratch\n\n- https://github.com/gusye1234/LightGCN-PyTorch\n\n- https://github.com/SytzeAndr/NGCF_RP32/blob/hand-in/NGCF.ipynb\n","metadata":{"id":"6RNPSfjWjV25"}}]}